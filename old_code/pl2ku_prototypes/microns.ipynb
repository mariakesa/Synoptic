{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'meshparty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcaveclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CAVEclient\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcaveclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CAVEclient\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmeshparty\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m skeleton_io\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Initialize CAVEclient\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'meshparty'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_swc_to_graph(swc_file):\n",
    "    df = pd.read_csv(\n",
    "        swc_file,\n",
    "        comment='#',\n",
    "        delim_whitespace=True,\n",
    "        names=[\"id\", \"type\", \"x\", \"y\", \"z\", \"radius\", \"parent\"]\n",
    "    )\n",
    "\n",
    "    G = nx.Graph()\n",
    "    node_positions = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        node_id = int(row[\"id\"])\n",
    "        parent_id = int(row[\"parent\"])\n",
    "        coord = np.array([row[\"x\"], row[\"y\"], row[\"z\"]])\n",
    "        node_positions[node_id] = coord\n",
    "        G.add_node(node_id)\n",
    "        if parent_id != -1:\n",
    "            parent_coord = node_positions[parent_id]\n",
    "            dist = np.linalg.norm(coord - parent_coord)\n",
    "            G.add_edge(parent_id, node_id, weight=dist)\n",
    "\n",
    "    return G, node_positions\n",
    "\n",
    "\n",
    "def compute_synaptic_embeddings(\n",
    "    client,\n",
    "    segment_id,\n",
    "    nucleus_id,\n",
    "    skel_path,\n",
    "    k=20,\n",
    "    alpha=1.0,\n",
    "    synapse_table_name='synapse_table',\n",
    "    output_csv_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute synaptic embeddings for a given neuron based on its morphology and synapses.\n",
    "\n",
    "    Parameters:\n",
    "    - client: Initialized CAVEclient object\n",
    "    - segment_id: Root ID of the neuron\n",
    "    - nucleus_id: Nucleus ID (for SWC filename)\n",
    "    - skel_path: Path to the skeleton SWC file\n",
    "    - k: Number of Laplacian modes (default 20)\n",
    "    - alpha: Fractional exponent (currently unused, placeholder for future extension)\n",
    "    - synapse_table_name: Name of the synapse table\n",
    "    - output_csv_path: If given, save the embeddings to this CSV file\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame of synapse embeddings\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import networkx as nx\n",
    "    from scipy.sparse.linalg import eigsh\n",
    "    from sklearn.neighbors import KDTree\n",
    "    from neuron_morphology.swc_io import read_swc\n",
    "\n",
    "    # Step 1: Load skeleton and build graph\n",
    "    skel_file = f\"{skel_path}/{segment_id}.swc\"\n",
    "\n",
    "    G, node_positions = load_swc_to_graph(skel_file)\n",
    "\n",
    "    for src, tgt in edges:\n",
    "        dist = np.linalg.norm(node_positions[src] - node_positions[tgt])\n",
    "        G.add_edge(src, tgt, weight=dist)\n",
    "\n",
    "    # Step 2: Compute Laplacian and eigenvectors\n",
    "    L = nx.laplacian_matrix(G, weight='weight')\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=k, which='SM')\n",
    "\n",
    "    # Step 3: Query only relevant synapses\n",
    "    synapse_df = client.materialize.query_table(\n",
    "        synapse_table_name,\n",
    "        split_positions=True,\n",
    "        filter_in_dict={'post_pt_root_id': [segment_id]}\n",
    "    )\n",
    "\n",
    "    if synapse_df.empty:\n",
    "        print(f\"No synapses found for segment ID {segment_id}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Step 4: Map synapses to nearest nodes\n",
    "    skeleton_coords = np.array(list(node_positions.values()))\n",
    "    tree = KDTree(skeleton_coords)\n",
    "    synapse_coords = synapse_df[['x', 'y', 'z']].values\n",
    "    distances, indices = tree.query(synapse_coords, k=1)\n",
    "    nearest_nodes = [list(node_positions.keys())[idx[0]] for idx in indices]\n",
    "\n",
    "    # Step 5: Embed synapses\n",
    "    embeddings = []\n",
    "    for node_id in nearest_nodes:\n",
    "        node_index = list(G.nodes).index(node_id)\n",
    "        embedding = eigenvectors[node_index] / eigenvalues\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    embedding_df = pd.DataFrame(embeddings, columns=[f'mode_{i+1}' for i in range(k)])\n",
    "    embedding_df['synapse_id'] = synapse_df['id'].values\n",
    "\n",
    "    if output_csv_path:\n",
    "        embedding_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    return embedding_df\n",
    "\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "from caveclient import CAVEclient\n",
    "from meshparty import skeleton_io\n",
    "import os\n",
    "\n",
    "# Initialize CAVEclient\n",
    "client = CAVEclient('minnie65_public')\n",
    "\n",
    "# Segment ID of the neuron\n",
    "segment_id = 864691135122603047\n",
    "\n",
    "# Directory to save\n",
    "save_dir = \"/data\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Pull the skeleton\n",
    "skeleton = client.materialize.get_skeleton(segment_id)\n",
    "\n",
    "# Save as SWC file\n",
    "swc_path = os.path.join(save_dir, f\"{segment_id}.swc\")\n",
    "skeleton_io.write_swc(skeleton, swc_path)\n",
    "\n",
    "print(f\"Saved SWC to: {swc_path}\")\n",
    "\n",
    "\n",
    "client = CAVEclient('minnie65_public')\n",
    "segment_id = 864691135122603047\n",
    "nucleus_id = 292685\n",
    "skel_path = \"/data\"\n",
    "\n",
    "df = compute_synaptic_embeddings(\n",
    "    client,\n",
    "    segment_id=segment_id,\n",
    "    nucleus_id=nucleus_id,\n",
    "    skel_path=skel_path,\n",
    "    k=20,\n",
    "    output_csv_path=\"synaptic_embedding.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChunkedGraphClient' object has no attribute 'get_skeleton'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m segment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m864691135122603047\u001b[39m\n\u001b[1;32m     39\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/864691135122603047.swc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[43msave_skeleton_as_swc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36msave_skeleton_as_swc\u001b[0;34m(client, segment_id, save_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcaveclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CAVEclient\n\u001b[1;32m     13\u001b[0m client \u001b[38;5;241m=\u001b[39m CAVEclient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminnie65_public\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m skel \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunkedgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_skeleton\u001b[49m(segment_id)\n\u001b[1;32m     16\u001b[0m vertices \u001b[38;5;241m=\u001b[39m skel\u001b[38;5;241m.\u001b[39mvertices\n\u001b[1;32m     17\u001b[0m edges \u001b[38;5;241m=\u001b[39m skel\u001b[38;5;241m.\u001b[39medges\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChunkedGraphClient' object has no attribute 'get_skeleton'"
     ]
    }
   ],
   "source": [
    "from caveclient import CAVEclient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from caveclient import CAVEclient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_skeleton_as_swc(client, segment_id, save_path):\n",
    "    from caveclient import CAVEclient\n",
    "    client = CAVEclient(\"minnie65_public\")\n",
    "    skel = client.chunkedgraph.get_skeleton(segment_id)\n",
    "\n",
    "    vertices = skel.vertices\n",
    "    edges = skel.edges\n",
    "\n",
    "    node_ids = np.arange(len(vertices))\n",
    "    parent_map = {child: parent for parent, child in edges}\n",
    "\n",
    "    swc_rows = []\n",
    "    for i, (x, y, z) in enumerate(vertices):\n",
    "        swc_id = node_ids[i]\n",
    "        swc_type = 3  # dendrite\n",
    "        radius = 1.0\n",
    "        parent = parent_map.get(swc_id, -1)\n",
    "        swc_rows.append([swc_id, swc_type, x, y, z, radius, parent])\n",
    "\n",
    "    swc_df = pd.DataFrame(swc_rows, columns=[\"id\", \"type\", \"x\", \"y\", \"z\", \"radius\", \"parent\"])\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    swc_df.to_csv\n",
    "\n",
    "\n",
    "\n",
    "# Usage\n",
    "client = CAVEclient(\"minnie65_public\")\n",
    "segment_id = 864691135122603047\n",
    "save_path = \"/data/864691135122603047.swc\"\n",
    "\n",
    "save_skeleton_as_swc(client, segment_id, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 01:48:58,373 root         INFO     get_versions()\n",
      "2025-04-17 01:48:58,374 root         INFO     endpoint: {skeleton_server_address}/skeletoncache/api/versions\n",
      "2025-04-17 01:48:58,374 root         INFO     url: https://minnie.microns-daf.com/skeletoncache/api/versions\n",
      "2025-04-17 01:48:58,578 root         INFO     response: <Response [200]>\n",
      "2025-04-17 01:48:58,579 root         INFO     versions: <class 'list'> [-1, 0, 1, 2, 3, 4]\n",
      "2025-04-17 01:48:58,579 root         INFO     SkeletonService version: 0.18.1\n",
      "2025-04-17 01:49:00,080 root         INFO     get_skeleton() response contains content of size 108925 bytes\n"
     ]
    }
   ],
   "source": [
    "from caveclient import CAVEclient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "client = CAVEclient(\"minnie65_public\")\n",
    "\n",
    "# specify the materialization version, for consistency across time\",\n",
    "client.version = 1300\n",
    "\n",
    "# Example: pyramidal cell in v1300\n",
    "example_cell_id = 864691135572530981\n",
    "\n",
    "sk_df = client.skeleton.get_skeleton(example_cell_id, output_format='swc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'meshparty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmeshparty\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m meshwork\n\u001b[1;32m      2\u001b[0m mw \u001b[38;5;241m=\u001b[39m meshwork\u001b[38;5;241m.\u001b[39mload_meshwork(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3://bossdb-open-data/iarpa_microns/minnie/minnie65/skeletons/v661/meshworks/864691135122603047.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'meshparty'"
     ]
    }
   ],
   "source": [
    "from meshparty import meshwork\n",
    "mw = meshwork.load_meshwork(\"s3://bossdb-open-data/iarpa_microns/minnie/minnie65/skeletons/v661/meshworks/864691135122603047.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".microns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
