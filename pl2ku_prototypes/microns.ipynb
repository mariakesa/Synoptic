{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'meshparty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcaveclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CAVEclient\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcaveclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CAVEclient\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmeshparty\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m skeleton_io\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Initialize CAVEclient\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'meshparty'"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_swc_to_graph(swc_file):\n",
    "    df = pd.read_csv(\n",
    "        swc_file,\n",
    "        comment='#',\n",
    "        delim_whitespace=True,\n",
    "        names=[\"id\", \"type\", \"x\", \"y\", \"z\", \"radius\", \"parent\"]\n",
    "    )\n",
    "\n",
    "    G = nx.Graph()\n",
    "    node_positions = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        node_id = int(row[\"id\"])\n",
    "        parent_id = int(row[\"parent\"])\n",
    "        coord = np.array([row[\"x\"], row[\"y\"], row[\"z\"]])\n",
    "        node_positions[node_id] = coord\n",
    "        G.add_node(node_id)\n",
    "        if parent_id != -1:\n",
    "            parent_coord = node_positions[parent_id]\n",
    "            dist = np.linalg.norm(coord - parent_coord)\n",
    "            G.add_edge(parent_id, node_id, weight=dist)\n",
    "\n",
    "    return G, node_positions\n",
    "\n",
    "\n",
    "def compute_synaptic_embeddings(\n",
    "    client,\n",
    "    segment_id,\n",
    "    nucleus_id,\n",
    "    skel_path,\n",
    "    k=20,\n",
    "    alpha=1.0,\n",
    "    synapse_table_name='synapse_table',\n",
    "    output_csv_path=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute synaptic embeddings for a given neuron based on its morphology and synapses.\n",
    "\n",
    "    Parameters:\n",
    "    - client: Initialized CAVEclient object\n",
    "    - segment_id: Root ID of the neuron\n",
    "    - nucleus_id: Nucleus ID (for SWC filename)\n",
    "    - skel_path: Path to the skeleton SWC file\n",
    "    - k: Number of Laplacian modes (default 20)\n",
    "    - alpha: Fractional exponent (currently unused, placeholder for future extension)\n",
    "    - synapse_table_name: Name of the synapse table\n",
    "    - output_csv_path: If given, save the embeddings to this CSV file\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame of synapse embeddings\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import networkx as nx\n",
    "    from scipy.sparse.linalg import eigsh\n",
    "    from sklearn.neighbors import KDTree\n",
    "    from neuron_morphology.swc_io import read_swc\n",
    "\n",
    "    # Step 1: Load skeleton and build graph\n",
    "    skel_file = f\"{skel_path}/{segment_id}.swc\"\n",
    "\n",
    "    G, node_positions = load_swc_to_graph(skel_file)\n",
    "\n",
    "    for src, tgt in edges:\n",
    "        dist = np.linalg.norm(node_positions[src] - node_positions[tgt])\n",
    "        G.add_edge(src, tgt, weight=dist)\n",
    "\n",
    "    # Step 2: Compute Laplacian and eigenvectors\n",
    "    L = nx.laplacian_matrix(G, weight='weight')\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=k, which='SM')\n",
    "\n",
    "    # Step 3: Query only relevant synapses\n",
    "    synapse_df = client.materialize.query_table(\n",
    "        synapse_table_name,\n",
    "        split_positions=True,\n",
    "        filter_in_dict={'post_pt_root_id': [segment_id]}\n",
    "    )\n",
    "\n",
    "    if synapse_df.empty:\n",
    "        print(f\"No synapses found for segment ID {segment_id}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Step 4: Map synapses to nearest nodes\n",
    "    skeleton_coords = np.array(list(node_positions.values()))\n",
    "    tree = KDTree(skeleton_coords)\n",
    "    synapse_coords = synapse_df[['x', 'y', 'z']].values\n",
    "    distances, indices = tree.query(synapse_coords, k=1)\n",
    "    nearest_nodes = [list(node_positions.keys())[idx[0]] for idx in indices]\n",
    "\n",
    "    # Step 5: Embed synapses\n",
    "    embeddings = []\n",
    "    for node_id in nearest_nodes:\n",
    "        node_index = list(G.nodes).index(node_id)\n",
    "        embedding = eigenvectors[node_index] / eigenvalues\n",
    "        embeddings.append(embedding)\n",
    "\n",
    "    embedding_df = pd.DataFrame(embeddings, columns=[f'mode_{i+1}' for i in range(k)])\n",
    "    embedding_df['synapse_id'] = synapse_df['id'].values\n",
    "\n",
    "    if output_csv_path:\n",
    "        embedding_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    return embedding_df\n",
    "\n",
    "from caveclient import CAVEclient\n",
    "\n",
    "from caveclient import CAVEclient\n",
    "from meshparty import skeleton_io\n",
    "import os\n",
    "\n",
    "# Initialize CAVEclient\n",
    "client = CAVEclient('minnie65_public')\n",
    "\n",
    "# Segment ID of the neuron\n",
    "segment_id = 864691135122603047\n",
    "\n",
    "# Directory to save\n",
    "save_dir = \"/data\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Pull the skeleton\n",
    "skeleton = client.materialize.get_skeleton(segment_id)\n",
    "\n",
    "# Save as SWC file\n",
    "swc_path = os.path.join(save_dir, f\"{segment_id}.swc\")\n",
    "skeleton_io.write_swc(skeleton, swc_path)\n",
    "\n",
    "print(f\"Saved SWC to: {swc_path}\")\n",
    "\n",
    "\n",
    "client = CAVEclient('minnie65_public')\n",
    "segment_id = 864691135122603047\n",
    "nucleus_id = 292685\n",
    "skel_path = \"/data\"\n",
    "\n",
    "df = compute_synaptic_embeddings(\n",
    "    client,\n",
    "    segment_id=segment_id,\n",
    "    nucleus_id=nucleus_id,\n",
    "    skel_path=skel_path,\n",
    "    k=20,\n",
    "    output_csv_path=\"synaptic_embedding.csv\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".microns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
